{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-Natural Language Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing NLP Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n"
     ]
    }
   ],
   "source": [
    "text='Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.',\n",
       " 'The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.',\n",
       " 'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents=nltk.sent_tokenize(text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "['The', 'goal', 'is', 'a', 'computer', 'capable', 'of', '``', 'understanding', \"''\", 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.']\n",
      "['The', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.sent_tokenize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)Words Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'technology',\n",
       " 'can',\n",
       " 'then',\n",
       " 'accurately',\n",
       " 'extract',\n",
       " 'information',\n",
       " 'and',\n",
       " 'insights',\n",
       " 'contained',\n",
       " 'in',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'categorize',\n",
       " 'and',\n",
       " 'organize',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'themselves',\n",
       " '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=nltk.word_tokenize(sent)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)Token Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('going',wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'come'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('coming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stay'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('stayed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convey'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('conveyed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('better',wordnet.ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('ran',wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('going')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sws=sw.words('english')\n",
    "sws[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'technology',\n",
       " 'can',\n",
       " 'then',\n",
       " 'accurately',\n",
       " 'extract',\n",
       " 'information',\n",
       " 'and',\n",
       " 'insights',\n",
       " 'contained',\n",
       " 'in',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'categorize',\n",
       " 'and',\n",
       " 'organize',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'themselves',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'technolog',\n",
       " 'accur',\n",
       " 'extract',\n",
       " 'inform',\n",
       " 'insight',\n",
       " 'contain',\n",
       " 'document',\n",
       " 'well',\n",
       " 'categor',\n",
       " 'organ',\n",
       " 'document',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stemmer.stem(word) for word in words if word not in sws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'technology',\n",
       " 'accurately',\n",
       " 'extract',\n",
       " 'information',\n",
       " 'insights',\n",
       " 'contained',\n",
       " 'documents',\n",
       " 'well',\n",
       " 'categorize',\n",
       " 'organize',\n",
       " 'documents',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in words if word not in sws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuations\n",
    "from string import punctuation as punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['technology',\n",
       " 'accurately',\n",
       " 'extract',\n",
       " 'information',\n",
       " 'insights',\n",
       " 'contained',\n",
       " 'documents',\n",
       " 'well',\n",
       " 'categorize',\n",
       " 'organize',\n",
       " 'documents']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in words if (word.lower() not in sws) and (word not in punc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing NLP subfield linguistics computer science artificial intelligence concerned interactions computers human language particular program computers process analyze large amounts natural language data', \"goal computer capable `` understanding '' contents documents including contextual nuances language within\", 'technology accurately extract information insights contained documents well categorize organize documents']\n"
     ]
    }
   ],
   "source": [
    "all_words=[]\n",
    "for sent in nltk.sent_tokenize(text):\n",
    "    words=nltk.word_tokenize(sent)\n",
    "    words=[word for word in words if (word.lower() not in sws) and (word not in punc)]\n",
    "    all_words+= [' '.join(words)]    #joining words again to create sentence bec,cv takes imput as sentences\n",
    "    #print(words)\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow=cv.fit_transform(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accurately',\n",
       " 'amounts',\n",
       " 'analyze',\n",
       " 'artificial',\n",
       " 'capable',\n",
       " 'categorize',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'concerned',\n",
       " 'contained',\n",
       " 'contents',\n",
       " 'contextual',\n",
       " 'data',\n",
       " 'documents',\n",
       " 'extract',\n",
       " 'goal',\n",
       " 'human',\n",
       " 'including',\n",
       " 'information',\n",
       " 'insights',\n",
       " 'intelligence',\n",
       " 'interactions',\n",
       " 'language',\n",
       " 'large',\n",
       " 'linguistics',\n",
       " 'natural',\n",
       " 'nlp',\n",
       " 'nuances',\n",
       " 'organize',\n",
       " 'particular',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'program',\n",
       " 'science',\n",
       " 'subfield',\n",
       " 'technology',\n",
       " 'understanding',\n",
       " 'well',\n",
       " 'within']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names=cv.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing NLP subfield linguistics computer science artificial intelligence concerned interactions computers human language particular program computers process analyze large amounts natural language data',\n",
       " \"goal computer capable `` understanding '' contents documents including contextual nuances language within\",\n",
       " 'technology accurately extract information insights contained documents well categorize organize documents']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accurately</th>\n",
       "      <th>amounts</th>\n",
       "      <th>analyze</th>\n",
       "      <th>artificial</th>\n",
       "      <th>capable</th>\n",
       "      <th>categorize</th>\n",
       "      <th>computer</th>\n",
       "      <th>computers</th>\n",
       "      <th>concerned</th>\n",
       "      <th>contained</th>\n",
       "      <th>...</th>\n",
       "      <th>particular</th>\n",
       "      <th>process</th>\n",
       "      <th>processing</th>\n",
       "      <th>program</th>\n",
       "      <th>science</th>\n",
       "      <th>subfield</th>\n",
       "      <th>technology</th>\n",
       "      <th>understanding</th>\n",
       "      <th>well</th>\n",
       "      <th>within</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accurately  amounts  analyze  artificial  capable  categorize  computer  \\\n",
       "0           0        1        1           1        0           0         1   \n",
       "1           0        0        0           0        1           0         1   \n",
       "2           1        0        0           0        0           1         0   \n",
       "\n",
       "   computers  concerned  contained  ...  particular  process  processing  \\\n",
       "0          2          1          0  ...           1        1           1   \n",
       "1          0          0          0  ...           0        0           0   \n",
       "2          0          0          1  ...           0        0           0   \n",
       "\n",
       "   program  science  subfield  technology  understanding  well  within  \n",
       "0        1        1         1           0              0     0       0  \n",
       "1        0        0         0           0              1     0       1  \n",
       "2        0        0         0           1              0     1       0  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bow.toarray(),columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfV = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf =tfidfV.fit_transform(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accurately</th>\n",
       "      <th>amounts</th>\n",
       "      <th>analyze</th>\n",
       "      <th>artificial</th>\n",
       "      <th>capable</th>\n",
       "      <th>categorize</th>\n",
       "      <th>computer</th>\n",
       "      <th>computers</th>\n",
       "      <th>concerned</th>\n",
       "      <th>contained</th>\n",
       "      <th>...</th>\n",
       "      <th>particular</th>\n",
       "      <th>process</th>\n",
       "      <th>processing</th>\n",
       "      <th>program</th>\n",
       "      <th>science</th>\n",
       "      <th>subfield</th>\n",
       "      <th>technology</th>\n",
       "      <th>understanding</th>\n",
       "      <th>well</th>\n",
       "      <th>within</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>0.360469</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.297303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297303</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.297303</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accurately   amounts   analyze  artificial  capable  categorize  computer  \\\n",
       "0    0.000000  0.180234  0.180234    0.180234   0.0000    0.000000  0.137073   \n",
       "1    0.000000  0.000000  0.000000    0.000000   0.3205    0.000000  0.243748   \n",
       "2    0.297303  0.000000  0.000000    0.000000   0.0000    0.297303  0.000000   \n",
       "\n",
       "   computers  concerned  contained  ...  particular   process  processing  \\\n",
       "0   0.360469   0.180234   0.000000  ...    0.180234  0.180234    0.180234   \n",
       "1   0.000000   0.000000   0.000000  ...    0.000000  0.000000    0.000000   \n",
       "2   0.000000   0.000000   0.297303  ...    0.000000  0.000000    0.000000   \n",
       "\n",
       "    program   science  subfield  technology  understanding      well  within  \n",
       "0  0.180234  0.180234  0.180234    0.000000         0.0000  0.000000  0.0000  \n",
       "1  0.000000  0.000000  0.000000    0.000000         0.3205  0.000000  0.3205  \n",
       "2  0.000000  0.000000  0.000000    0.297303         0.0000  0.297303  0.0000  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tf_idf.toarray(),columns=tfidfV.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
